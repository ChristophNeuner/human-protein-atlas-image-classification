{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../fastai/') #fastai version 1\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import pdb\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from matplotlib import patches, patheffects\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import png\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from resnet import Resnet4Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_rgby(path,id): #a function that reads RGBY image\n",
    "    colors = ['red','green','blue','yellow']\n",
    "    flags = cv2.IMREAD_GRAYSCALE\n",
    "    img = [cv2.imread(os.path.join(path, id+'_'+color+'.png'), flags).astype(np.float32)/255\n",
    "           for color in colors]\n",
    "    return np.stack(img, axis=-1)\n",
    "\n",
    "def pil2tensor(image,dtype:np.dtype)->TensorImage:\n",
    "    \"\"\"Convert [height, width, nchannels] style image array to torch style image tensor.\"\"\"\n",
    "    a = np.asarray(image)\n",
    "    if a.ndim==2: \n",
    "        a = np.expand_dims(a,2)\n",
    "    a = np.transpose(a, (1, 0, 2))\n",
    "    a = np.transpose(a, (2, 1, 0))\n",
    "    return torch.from_numpy( a.astype(dtype, copy=False) )\n",
    "\n",
    "def A(*a):\n",
    "    \"\"\"convert iterable object into numpy array\"\"\"\n",
    "    return np.array(a[0]) if len(a)==1 else [np.array(o) for o in a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "DP = Path('/home/Deep_Learner/work/datasets/human-protein-atlas-image-classification/')\n",
    "STAGE_ONE_DATA = DP/'stage1_data'\n",
    "TRAIN_PNGS = 'train_pngs'\n",
    "TRAIN_LABELS = 'labels.csv'\n",
    "TEST_PNGS = 'test_pngs'\n",
    "TRAIN_CSV = 'train.csv'\n",
    "SAMPLE_SUBMISSION_CSV = 'sample_submission.csv'\n",
    "\n",
    "\n",
    "SUBMISSIONS = DP/STAGE_ONE_DATA/'submissions'\n",
    "SUBMISSIONS.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "filter_colors = ['blue', 'green', 'red', 'yellow']\n",
    "\n",
    "IdToCatDict = {0:'Nucleoplasm',\n",
    "               1:'Nuclear_membrane',\n",
    "               2:'Nucleoli',\n",
    "               3:'Nucleoli_fibrillar_center',\n",
    "               4:'Nuclear_speckles',\n",
    "               5:'Nuclear_bodies',\n",
    "               6:'Endoplasmic_reticulum',\n",
    "               7:'Golgi_apparatus',\n",
    "               8:'Peroxisomes',\n",
    "               9:'Endosomes',\n",
    "               10:'Lysosomes',\n",
    "               11:'Intermediate_filaments',\n",
    "               12:'Actin_filaments',\n",
    "               13:'Focal_adhesion_sites',\n",
    "               14:'Microtubules',\n",
    "               15:'Microtubule_ends',\n",
    "               16:'Cytokinetic_bridge',\n",
    "               17:'Mitotic_spindle',\n",
    "               18:'Microtubule_organizing_center',\n",
    "               19:'Centrosome',\n",
    "               20:'Lipid_droplets',\n",
    "               21:'Plasma_membrane',\n",
    "               22:'Cell_junctions',\n",
    "               23:'Mitochondria',\n",
    "               24:'Aggresome',\n",
    "               25:'Cytosol',\n",
    "               26:'Cytoplasmic_bodies',\n",
    "               27:'Rods_&_rings'}\n",
    "\n",
    "sz = 224\n",
    "bs = 16\n",
    "val_split = 0.1\n",
    "train_names = list(pd.read_csv(STAGE_ONE_DATA/TRAIN_CSV)['Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(DatasetBase):\n",
    "    def __init__(self, \n",
    "                 path:pathlib.Path, \n",
    "                 csv_path:pathlib.Path, \n",
    "                 coloumn_idx_fns:int, \n",
    "                 coloumn_idx_targets:int, \n",
    "                 transforms:list, \n",
    "                 isTest:bool, \n",
    "                 img_size:int, \n",
    "                 classes:list, \n",
    "                 class2idx:Dict[Any,int]=None):\n",
    "        \"\"\"\n",
    "        write description here\n",
    "\n",
    "        # Arguments\n",
    "          path: pathlib.Path to images folder\n",
    "          csv_path: pathlib.Path to csv file with coloums of image ids (without the colour suffix) \n",
    "                      and the targets as integers separated with spaces\n",
    "          transforms: list of transform functions (e.g. from fastai.vision.transform)\n",
    "          isTest: specify if it is a test set and therefore does not have labels\n",
    "          coloumn_idx_fns: coloumn index in the csv file, where the filenames/fileindices are\n",
    "          coloumn_idx_targets: coloumn index in the csv file, where the targets are\n",
    "          img_size: size the images get resized to          \n",
    "        # Returns\n",
    "        \n",
    "        # Raises\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.coloumn_idx_fns = coloumn_idx_fns\n",
    "        self.coloumn_idx_targets = coloumn_idx_targets\n",
    "        self.transforms = transforms\n",
    "        self.isTest = isTest\n",
    "        self.sz = img_size\n",
    "        self.classes = classes\n",
    "        self.c = len(classes)\n",
    "        if class2idx is None: self.class2idx = {v:k for k,v in enumerate(self.classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):    \n",
    "        return self.__get_x(idx), self.__get_y(idx)\n",
    "\n",
    "    \n",
    "    def __get_x(self, idx):\n",
    "        img = open_rgby(self.path,self.df.iloc[idx, self.coloumn_idx_fns])\n",
    "        img = cv2.resize(img, (self.sz, self.sz),cv2.INTER_AREA)\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(data)\n",
    "        img = pil2tensor(img,np.float32)\n",
    "        img = Image(img)\n",
    "        return img\n",
    "    \n",
    "    def __get_y(self, idx):\n",
    "        if self.isTest:\n",
    "            return [-1]\n",
    "        labels = self.df.iloc[idx, self.coloumn_idx_targets].split()\n",
    "        labels = [int(s) for s in labels]\n",
    "        labels = np.asarray(labels)\n",
    "        labels = self.__one_hot_encode(labels)\n",
    "        return labels\n",
    "    \n",
    "    def __one_hot_encode(self, labels:np.array):\n",
    "        a = np.zeros(len(self.classes), dtype=np.int)\n",
    "        for i in labels:\n",
    "            a[i] = 1\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [RandTransform(tfm=TfmCrop (crop_pad), kwargs={'row_pct': (0, 1), 'col_pct': (0, 1)}, p=1.0, resolved={}, do_run=True, is_random=True),\n",
    "  RandTransform(tfm=TfmAffine (dihedral_affine), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True),\n",
    "  RandTransform(tfm=TfmCoord (symmetric_warp), kwargs={'magnitude': (-0.2, 0.2)}, p=0.75, resolved={}, do_run=True, is_random=True),\n",
    "  RandTransform(tfm=TfmAffine (rotate), kwargs={'degrees': (-10.0, 10.0)}, p=0.75, resolved={}, do_run=True, is_random=True),\n",
    "  RandTransform(tfm=TfmAffine (zoom), kwargs={'row_pct': (0, 1), 'col_pct': (0, 1), 'scale': (1.0, 1.1)}, p=0.75, resolved={}, do_run=True, is_random=True),\n",
    "  RandTransform(tfm=TfmLighting (brightness), kwargs={'change': (0.4, 0.6)}, p=0.75, resolved={}, do_run=True, is_random=True),\n",
    "  RandTransform(tfm=TfmLighting (contrast), kwargs={'scale': (0.8, 1.25)}, p=0.75, resolved={}, do_run=True, is_random=True),\n",
    "  RandTransform(tfm=TfmCrop (crop_pad), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(path=STAGE_ONE_DATA/TRAIN_PNGS, \n",
    "                        csv_path=STAGE_ONE_DATA/TRAIN_CSV, \n",
    "                        coloumn_idx_fns=0, \n",
    "                        coloumn_idx_targets=1, \n",
    "                        transforms=None, \n",
    "                        isTest=False, \n",
    "                        img_size=sz, \n",
    "                        classes=list(IdToCatDict.values()))\n",
    "\n",
    "dataset_test = CustomDataset(path=STAGE_ONE_DATA/TEST_PNGS, \n",
    "                        csv_path=STAGE_ONE_DATA/SAMPLE_SUBMISSION_CSV, \n",
    "                        coloumn_idx_fns=0, \n",
    "                        coloumn_idx_targets=1, \n",
    "                        transforms=None, \n",
    "                        isTest=True, \n",
    "                        img_size=sz,\n",
    "                        classes=list(IdToCatDict.values()))\n",
    "\n",
    "tr_idxs, val_idxs = train_test_split(np.arange(len(train_names)), test_size=val_split, random_state=42)\n",
    "train_sampler = SubsetRandomSampler(tr_idxs)\n",
    "val_sampler = SubsetRandomSampler(val_idxs)\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=bs, sampler=train_sampler, num_workers=6)\n",
    "val_loader = DataLoader(dataset=dataset, batch_size=bs, sampler=val_sampler, num_workers=6)\n",
    "test_loader = DataLoader(dataset=dataset_test, batch_size=bs, num_workers=4)\n",
    "\n",
    "\n",
    "\n",
    "bunch = ImageDataBunch(train_dl=train_loader, \n",
    "                       valid_dl=val_loader, \n",
    "                       test_dl=test_loader, \n",
    "                       device=None, \n",
    "                       tfms=None, \n",
    "                       path=STAGE_ONE_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: calculate stats for normalization\n",
    "\n",
    "stats = A([0.08069, 0.05258, 0.05487, 0.08282], [0.13704, 0.10145, 0.15313, 0.13814])\n",
    "bunch.normalize(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bunch.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()\n",
    "    \n",
    "def acc(preds,targs,th=0.0):\n",
    "    preds = (preds > th).int()\n",
    "    targs = targs.int()\n",
    "    return (preds==targs).float().mean()\n",
    "\n",
    "f1_score = partial(fbeta, thresh=0.5, beta=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet34 = Resnet4Channel(encoder_depth=34, pretrained=True, num_classes=bunch.train_ds.c)\n",
    "#learner = create_cnn(data=bunch, arch=cu, metrics=[acc])\n",
    "#learner.opt_func = optim.Adam\n",
    "#learner.loss_func = FocalLoss()\n",
    "\n",
    "learner = ClassificationLearner(\n",
    "    data=bunch,\n",
    "    model=resnet34,\n",
    "    loss_func=F.binary_cross_entropy_with_logits,\n",
    "    #loss_func=FocalLoss(),\n",
    "    path=STAGE_ONE_DATA,    \n",
    "    metrics=[f1_score], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Obsolete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(STAGE_ONE_DATA/TRAIN_LABELS):\n",
    "    trainFns_df = pd.read_csv(STAGE_ONE_DATA/TRAIN_LABELS)\n",
    "\n",
    "else:\n",
    "    trainIds_df = pd.read_csv(DP/'train.csv')\n",
    "    trainFns_df = pd.DataFrame(columns=['name','label'])\n",
    "    \n",
    "    for index, row in tqdm(trainIds_df.iterrows(), total=trainIds_df.shape[0]):\n",
    "        bn = row['Id']\n",
    "        cats = row['Target']\n",
    "        for c in filter_colors:\n",
    "            fn = f'{bn}_{c}'\n",
    "            trainFns_df = trainFns_df.append({'name': fn, 'label': cats}, ignore_index=True)\n",
    "            \n",
    "    trainFns_df.to_csv(STAGE_ONE_DATA/TRAIN_LABELS, index=False)\n",
    "\n",
    "\n",
    "trainFns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms(flip_vert=True)\n",
    "stage1_data = ImageDataBunch.from_csv(path=STAGE_ONE_DATA, \n",
    "                                      folder=TRAIN_PNGS, \n",
    "                                      suffix='.png', \n",
    "                                      test=TEST_PNGS, \n",
    "                                      ds_tfms=tfms, \n",
    "                                      size=sz,\n",
    "                                      valid_pct=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stage1_data.show_batch(rows=5, figsize=(25,25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner = create_cnn(stage1_data, models.resnet152, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-2*1.8\n",
    "lrs = np.array([lr/100,lr/10,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.lr_find(start_lr=lrs/1000, end_lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "callbacks = [ReduceLROnPlateauCallback(learn=learner, patience=8)]\n",
    "learner.fit(epochs=100, lr=lrs, callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "295px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
