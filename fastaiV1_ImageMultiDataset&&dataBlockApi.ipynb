{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.sys.path.append('../fastai/') #fastai version 1\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.image import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DP = Path('/home/Deep_Learner/work/datasets/human-protein-atlas-image-classification/')\n",
    "STAGE_ONE_DATA = DP/'stage1_data'\n",
    "TRAIN_PNGS = 'train_pngs_512'\n",
    "TEST_PNGS = 'test_pngs_512'\n",
    "TRAIN_CSV = 'train.csv'\n",
    "SAMPLE_SUBMISSION_CSV = 'sample_submission.csv'\n",
    "\n",
    "\n",
    "SUBMISSIONS = DP/STAGE_ONE_DATA/'submissions'\n",
    "SUBMISSIONS.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "filter_colors = ['blue', 'green', 'red', 'yellow']\n",
    "\n",
    "IdToCatDict = {0:'Nucleoplasm',\n",
    "               1:'Nuclear_membrane',\n",
    "               2:'Nucleoli',\n",
    "               3:'Nucleoli_fibrillar_center',\n",
    "               4:'Nuclear_speckles',\n",
    "               5:'Nuclear_bodies',\n",
    "               6:'Endoplasmic_reticulum',\n",
    "               7:'Golgi_apparatus',\n",
    "               8:'Peroxisomes',\n",
    "               9:'Endosomes',\n",
    "               10:'Lysosomes',\n",
    "               11:'Intermediate_filaments',\n",
    "               12:'Actin_filaments',\n",
    "               13:'Focal_adhesion_sites',\n",
    "               14:'Microtubules',\n",
    "               15:'Microtubule_ends',\n",
    "               16:'Cytokinetic_bridge',\n",
    "               17:'Mitotic_spindle',\n",
    "               18:'Microtubule_organizing_center',\n",
    "               19:'Centrosome',\n",
    "               20:'Lipid_droplets',\n",
    "               21:'Plasma_membrane',\n",
    "               22:'Cell_junctions',\n",
    "               23:'Mitochondria',\n",
    "               24:'Aggresome',\n",
    "               25:'Cytosol',\n",
    "               26:'Cytoplasmic_bodies',\n",
    "               27:'Rods_&_rings'}\n",
    "\n",
    "sz = 512\n",
    "original_img_sz = 512\n",
    "bs = 16\n",
    "val_split = 0.2\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_4_channel(fname):\n",
    "    fname = str(fname)\n",
    "    # strip extension before adding color\n",
    "    if fname.endswith('.png'):\n",
    "        fname = fname[:-4]\n",
    "    colors = ['red','green','blue','yellow']\n",
    "    flags = cv2.IMREAD_GRAYSCALE\n",
    "    img = [cv2.imread(fname+'_'+color+'.png', flags).astype(np.float32)/255\n",
    "           for color in colors]\n",
    "    \n",
    "    x = np.stack(img, axis=-1)\n",
    "    return Image(pil2tensor(x, np.float32).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class ImageMulti4Channel(ImageMultiDataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fastai/fastai/vision/data.py:122: UserWarning: `ImageMultiDataset` is deprecated and will soon be removed. Use the data block API.\n",
      "  warnings.warn(\"`ImageMultiDataset` is deprecated and will soon be removed. Use the data block API.\")\n"
     ]
    }
   ],
   "source": [
    "class ImageMulti4Channel(ImageMultiDataset):\n",
    "    def __init__(self, fns, labels, classes=None, **kwargs):\n",
    "        super().__init__(fns, labels, classes, **kwargs)\n",
    "        self.image_opener = open_4_channel\n",
    "        \n",
    "df = pd.read_csv(STAGE_ONE_DATA/TRAIN_CSV)\n",
    "fns = pd.Series([id + '.png' for id in df.Id])\n",
    "labels = [targ.split(' ') for targ in df.Target]\n",
    "trn_ds, val_ds = ImageMulti4Channel.from_folder(path=STAGE_ONE_DATA,\n",
    "                                                folder=TRAIN_PNGS, \n",
    "                                                fns=fns, \n",
    "                                                labels=labels,\n",
    "                                                valid_pct = val_split,\n",
    "                                                classes=[str(i) for i in range(28)])\n",
    "\n",
    "df_test = pd.read_csv(STAGE_ONE_DATA/SAMPLE_SUBMISSION_CSV)\n",
    "fns_test = pd.Series([id + '.png' for id in df_test.Id])\n",
    "labels_test = [str(targ).split(' ') for targ in df_test.Predicted]\n",
    "test_ds,_ = ImageMulti4Channel.from_folder(\n",
    "    path = STAGE_ONE_DATA, \n",
    "    folder=TEST_PNGS, \n",
    "    fns=fns_test, \n",
    "    labels=labels_test,\n",
    "    valid_pct=0,\n",
    "    classes=['0'])\n",
    "\n",
    "trn_tfms,_ = get_transforms(do_flip=True, flip_vert=True, max_rotate=30., max_zoom=1,\n",
    "                      max_lighting=0.05, max_warp=0.)\n",
    "\n",
    "protein_stats = ([0.08069, 0.05258, 0.05487, 0.08282], [0.13704, 0.10145, 0.15313, 0.13814])\n",
    "\n",
    "data = ImageDataBunch.create(trn_ds, \n",
    "                             val_ds, \n",
    "                             test_ds=test_ds, \n",
    "                             path=STAGE_ONE_DATA, \n",
    "                             bs=bs, \n",
    "                             ds_tfms=(trn_tfms, []), \n",
    "                             num_workers=8, size=sz).normalize(protein_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fastai data_block api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vision.data.open_image = open_4_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = ImageFileList.from_csv(path=STAGE_ONE_DATA, \n",
    "                               csv_name=TRAIN_CSV, \n",
    "                               col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = data.label_from_csv(csv_fname=TRAIN_CSV, \n",
    "                           fn_col=0, \n",
    "                           label_col=1, \n",
    "                           sep=' ', \n",
    "                           folder=TRAIN_PNGS, \n",
    "                           suffix='.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = data.random_split_by_pct(val_split)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data = data.add_test_folder(test_folder=TEST_PNGS, label=[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'x' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-a139abaa9b5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/fastai/fastai/data_block.py\u001b[0m in \u001b[0;36mdatasets\u001b[0;34m(self, dataset_cls, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;34m\"Create datasets from the underlying data using `dataset_cls` and passing along the `kwargs`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdataset_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mdss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mdss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'x' and 'y'"
     ]
    }
   ],
   "source": [
    "data = data.datasets()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageSplitData' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-77678c23b550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageSplitData' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "data = data.transform(tfms, size=sz)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageSplitData' object has no attribute 'databunch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-669b256aed4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageSplitData' object has no attribute 'databunch'"
     ]
    }
   ],
   "source": [
    "data = data.databunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function/Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.sum(dim=1).mean()\n",
    "\n",
    "\n",
    "f1_score = partial(fbeta, thresh=0.5, beta=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESNET_ENCODERS = {\n",
    "    34: torchvision.models.resnet34,\n",
    "    50: torchvision.models.resnet50,\n",
    "    101: torchvision.models.resnet101,\n",
    "    152: torchvision.models.resnet152,\n",
    "}\n",
    "\n",
    "\n",
    "class Resnet4Channel(nn.Module):\n",
    "    def __init__(self, encoder_depth=34, pretrained=True, num_classes=28):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = RESNET_ENCODERS[encoder_depth](pretrained=pretrained)\n",
    "        \n",
    "        w = self.encoder.conv1.weight\n",
    "        self.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.conv1.weight = nn.Parameter(torch.cat((w,torch.zeros(64,1,7,7)),dim=1))\n",
    "        \n",
    "        self.bn1 = self.encoder.bn1\n",
    "        self.relu = nn.ReLU(inplace=True) \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self.encoder.layer1\n",
    "        self.layer2 = self.encoder.layer2\n",
    "        self.layer3 = self.encoder.layer3\n",
    "        self.layer4 = self.encoder.layer4\n",
    "        \n",
    "        self.avgpool = self.encoder.avgpool\n",
    "        self.fc = nn.Linear(512 * (1 if encoder_depth==34 else 4), num_classes)        \n",
    "        \n",
    "        #self.custom_head = fastai.vision.learner.create_head(nf = 512 * (1 if encoder_depth==34 else 4)*2, nc = num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        #x = self.custom_head(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]          12,544\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "       BatchNorm2d-3         [-1, 64, 256, 256]             128\n",
      "              ReLU-4         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-5         [-1, 64, 128, 128]               0\n",
      "            Conv2d-6         [-1, 64, 128, 128]           4,096\n",
      "            Conv2d-7         [-1, 64, 128, 128]           4,096\n",
      "       BatchNorm2d-8         [-1, 64, 128, 128]             128\n",
      "       BatchNorm2d-9         [-1, 64, 128, 128]             128\n",
      "             ReLU-10         [-1, 64, 128, 128]               0\n",
      "             ReLU-11         [-1, 64, 128, 128]               0\n",
      "           Conv2d-12         [-1, 64, 128, 128]          36,864\n",
      "           Conv2d-13         [-1, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-14         [-1, 64, 128, 128]             128\n",
      "      BatchNorm2d-15         [-1, 64, 128, 128]             128\n",
      "             ReLU-16         [-1, 64, 128, 128]               0\n",
      "             ReLU-17         [-1, 64, 128, 128]               0\n",
      "           Conv2d-18        [-1, 256, 128, 128]          16,384\n",
      "           Conv2d-19        [-1, 256, 128, 128]          16,384\n",
      "      BatchNorm2d-20        [-1, 256, 128, 128]             512\n",
      "      BatchNorm2d-21        [-1, 256, 128, 128]             512\n",
      "           Conv2d-22        [-1, 256, 128, 128]          16,384\n",
      "           Conv2d-23        [-1, 256, 128, 128]          16,384\n",
      "      BatchNorm2d-24        [-1, 256, 128, 128]             512\n",
      "      BatchNorm2d-25        [-1, 256, 128, 128]             512\n",
      "             ReLU-26        [-1, 256, 128, 128]               0\n",
      "             ReLU-27        [-1, 256, 128, 128]               0\n",
      "       Bottleneck-28        [-1, 256, 128, 128]               0\n",
      "       Bottleneck-29        [-1, 256, 128, 128]               0\n",
      "           Conv2d-30         [-1, 64, 128, 128]          16,384\n",
      "           Conv2d-31         [-1, 64, 128, 128]          16,384\n",
      "      BatchNorm2d-32         [-1, 64, 128, 128]             128\n",
      "      BatchNorm2d-33         [-1, 64, 128, 128]             128\n",
      "             ReLU-34         [-1, 64, 128, 128]               0\n",
      "             ReLU-35         [-1, 64, 128, 128]               0\n",
      "           Conv2d-36         [-1, 64, 128, 128]          36,864\n",
      "           Conv2d-37         [-1, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-38         [-1, 64, 128, 128]             128\n",
      "      BatchNorm2d-39         [-1, 64, 128, 128]             128\n",
      "             ReLU-40         [-1, 64, 128, 128]               0\n",
      "             ReLU-41         [-1, 64, 128, 128]               0\n",
      "           Conv2d-42        [-1, 256, 128, 128]          16,384\n",
      "           Conv2d-43        [-1, 256, 128, 128]          16,384\n",
      "      BatchNorm2d-44        [-1, 256, 128, 128]             512\n",
      "      BatchNorm2d-45        [-1, 256, 128, 128]             512\n",
      "             ReLU-46        [-1, 256, 128, 128]               0\n",
      "             ReLU-47        [-1, 256, 128, 128]               0\n",
      "       Bottleneck-48        [-1, 256, 128, 128]               0\n",
      "       Bottleneck-49        [-1, 256, 128, 128]               0\n",
      "           Conv2d-50         [-1, 64, 128, 128]          16,384\n",
      "           Conv2d-51         [-1, 64, 128, 128]          16,384\n",
      "      BatchNorm2d-52         [-1, 64, 128, 128]             128\n",
      "      BatchNorm2d-53         [-1, 64, 128, 128]             128\n",
      "             ReLU-54         [-1, 64, 128, 128]               0\n",
      "             ReLU-55         [-1, 64, 128, 128]               0\n",
      "           Conv2d-56         [-1, 64, 128, 128]          36,864\n",
      "           Conv2d-57         [-1, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-58         [-1, 64, 128, 128]             128\n",
      "      BatchNorm2d-59         [-1, 64, 128, 128]             128\n",
      "             ReLU-60         [-1, 64, 128, 128]               0\n",
      "             ReLU-61         [-1, 64, 128, 128]               0\n",
      "           Conv2d-62        [-1, 256, 128, 128]          16,384\n",
      "           Conv2d-63        [-1, 256, 128, 128]          16,384\n",
      "      BatchNorm2d-64        [-1, 256, 128, 128]             512\n",
      "      BatchNorm2d-65        [-1, 256, 128, 128]             512\n",
      "             ReLU-66        [-1, 256, 128, 128]               0\n",
      "             ReLU-67        [-1, 256, 128, 128]               0\n",
      "       Bottleneck-68        [-1, 256, 128, 128]               0\n",
      "       Bottleneck-69        [-1, 256, 128, 128]               0\n",
      "           Conv2d-70        [-1, 128, 128, 128]          32,768\n",
      "           Conv2d-71        [-1, 128, 128, 128]          32,768\n",
      "      BatchNorm2d-72        [-1, 128, 128, 128]             256\n",
      "      BatchNorm2d-73        [-1, 128, 128, 128]             256\n",
      "             ReLU-74        [-1, 128, 128, 128]               0\n",
      "             ReLU-75        [-1, 128, 128, 128]               0\n",
      "           Conv2d-76          [-1, 128, 64, 64]         147,456\n",
      "           Conv2d-77          [-1, 128, 64, 64]         147,456\n",
      "      BatchNorm2d-78          [-1, 128, 64, 64]             256\n",
      "      BatchNorm2d-79          [-1, 128, 64, 64]             256\n",
      "             ReLU-80          [-1, 128, 64, 64]               0\n",
      "             ReLU-81          [-1, 128, 64, 64]               0\n",
      "           Conv2d-82          [-1, 512, 64, 64]          65,536\n",
      "           Conv2d-83          [-1, 512, 64, 64]          65,536\n",
      "      BatchNorm2d-84          [-1, 512, 64, 64]           1,024\n",
      "      BatchNorm2d-85          [-1, 512, 64, 64]           1,024\n",
      "           Conv2d-86          [-1, 512, 64, 64]         131,072\n",
      "           Conv2d-87          [-1, 512, 64, 64]         131,072\n",
      "      BatchNorm2d-88          [-1, 512, 64, 64]           1,024\n",
      "      BatchNorm2d-89          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-90          [-1, 512, 64, 64]               0\n",
      "             ReLU-91          [-1, 512, 64, 64]               0\n",
      "       Bottleneck-92          [-1, 512, 64, 64]               0\n",
      "       Bottleneck-93          [-1, 512, 64, 64]               0\n",
      "           Conv2d-94          [-1, 128, 64, 64]          65,536\n",
      "           Conv2d-95          [-1, 128, 64, 64]          65,536\n",
      "      BatchNorm2d-96          [-1, 128, 64, 64]             256\n",
      "      BatchNorm2d-97          [-1, 128, 64, 64]             256\n",
      "             ReLU-98          [-1, 128, 64, 64]               0\n",
      "             ReLU-99          [-1, 128, 64, 64]               0\n",
      "          Conv2d-100          [-1, 128, 64, 64]         147,456\n",
      "          Conv2d-101          [-1, 128, 64, 64]         147,456\n",
      "     BatchNorm2d-102          [-1, 128, 64, 64]             256\n",
      "     BatchNorm2d-103          [-1, 128, 64, 64]             256\n",
      "            ReLU-104          [-1, 128, 64, 64]               0\n",
      "            ReLU-105          [-1, 128, 64, 64]               0\n",
      "          Conv2d-106          [-1, 512, 64, 64]          65,536\n",
      "          Conv2d-107          [-1, 512, 64, 64]          65,536\n",
      "     BatchNorm2d-108          [-1, 512, 64, 64]           1,024\n",
      "     BatchNorm2d-109          [-1, 512, 64, 64]           1,024\n",
      "            ReLU-110          [-1, 512, 64, 64]               0\n",
      "            ReLU-111          [-1, 512, 64, 64]               0\n",
      "      Bottleneck-112          [-1, 512, 64, 64]               0\n",
      "      Bottleneck-113          [-1, 512, 64, 64]               0\n",
      "          Conv2d-114          [-1, 128, 64, 64]          65,536\n",
      "          Conv2d-115          [-1, 128, 64, 64]          65,536\n",
      "     BatchNorm2d-116          [-1, 128, 64, 64]             256\n",
      "     BatchNorm2d-117          [-1, 128, 64, 64]             256\n",
      "            ReLU-118          [-1, 128, 64, 64]               0\n",
      "            ReLU-119          [-1, 128, 64, 64]               0\n",
      "          Conv2d-120          [-1, 128, 64, 64]         147,456\n",
      "          Conv2d-121          [-1, 128, 64, 64]         147,456\n",
      "     BatchNorm2d-122          [-1, 128, 64, 64]             256\n",
      "     BatchNorm2d-123          [-1, 128, 64, 64]             256\n",
      "            ReLU-124          [-1, 128, 64, 64]               0\n",
      "            ReLU-125          [-1, 128, 64, 64]               0\n",
      "          Conv2d-126          [-1, 512, 64, 64]          65,536\n",
      "          Conv2d-127          [-1, 512, 64, 64]          65,536\n",
      "     BatchNorm2d-128          [-1, 512, 64, 64]           1,024\n",
      "     BatchNorm2d-129          [-1, 512, 64, 64]           1,024\n",
      "            ReLU-130          [-1, 512, 64, 64]               0\n",
      "            ReLU-131          [-1, 512, 64, 64]               0\n",
      "      Bottleneck-132          [-1, 512, 64, 64]               0\n",
      "      Bottleneck-133          [-1, 512, 64, 64]               0\n",
      "          Conv2d-134          [-1, 128, 64, 64]          65,536\n",
      "          Conv2d-135          [-1, 128, 64, 64]          65,536\n",
      "     BatchNorm2d-136          [-1, 128, 64, 64]             256\n",
      "     BatchNorm2d-137          [-1, 128, 64, 64]             256\n",
      "            ReLU-138          [-1, 128, 64, 64]               0\n",
      "            ReLU-139          [-1, 128, 64, 64]               0\n",
      "          Conv2d-140          [-1, 128, 64, 64]         147,456\n",
      "          Conv2d-141          [-1, 128, 64, 64]         147,456\n",
      "     BatchNorm2d-142          [-1, 128, 64, 64]             256\n",
      "     BatchNorm2d-143          [-1, 128, 64, 64]             256\n",
      "            ReLU-144          [-1, 128, 64, 64]               0\n",
      "            ReLU-145          [-1, 128, 64, 64]               0\n",
      "          Conv2d-146          [-1, 512, 64, 64]          65,536\n",
      "          Conv2d-147          [-1, 512, 64, 64]          65,536\n",
      "     BatchNorm2d-148          [-1, 512, 64, 64]           1,024\n",
      "     BatchNorm2d-149          [-1, 512, 64, 64]           1,024\n",
      "            ReLU-150          [-1, 512, 64, 64]               0\n",
      "            ReLU-151          [-1, 512, 64, 64]               0\n",
      "      Bottleneck-152          [-1, 512, 64, 64]               0\n",
      "      Bottleneck-153          [-1, 512, 64, 64]               0\n",
      "          Conv2d-154          [-1, 256, 64, 64]         131,072\n",
      "          Conv2d-155          [-1, 256, 64, 64]         131,072\n",
      "     BatchNorm2d-156          [-1, 256, 64, 64]             512\n",
      "     BatchNorm2d-157          [-1, 256, 64, 64]             512\n",
      "            ReLU-158          [-1, 256, 64, 64]               0\n",
      "            ReLU-159          [-1, 256, 64, 64]               0\n",
      "          Conv2d-160          [-1, 256, 32, 32]         589,824\n",
      "          Conv2d-161          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-162          [-1, 256, 32, 32]             512\n",
      "     BatchNorm2d-163          [-1, 256, 32, 32]             512\n",
      "            ReLU-164          [-1, 256, 32, 32]               0\n",
      "            ReLU-165          [-1, 256, 32, 32]               0\n",
      "          Conv2d-166         [-1, 1024, 32, 32]         262,144\n",
      "          Conv2d-167         [-1, 1024, 32, 32]         262,144\n",
      "     BatchNorm2d-168         [-1, 1024, 32, 32]           2,048\n",
      "     BatchNorm2d-169         [-1, 1024, 32, 32]           2,048\n",
      "          Conv2d-170         [-1, 1024, 32, 32]         524,288\n",
      "          Conv2d-171         [-1, 1024, 32, 32]         524,288\n",
      "     BatchNorm2d-172         [-1, 1024, 32, 32]           2,048\n",
      "     BatchNorm2d-173         [-1, 1024, 32, 32]           2,048\n",
      "            ReLU-174         [-1, 1024, 32, 32]               0\n",
      "            ReLU-175         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-176         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-177         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-178          [-1, 256, 32, 32]         262,144\n",
      "          Conv2d-179          [-1, 256, 32, 32]         262,144\n",
      "     BatchNorm2d-180          [-1, 256, 32, 32]             512\n",
      "     BatchNorm2d-181          [-1, 256, 32, 32]             512\n",
      "            ReLU-182          [-1, 256, 32, 32]               0\n",
      "            ReLU-183          [-1, 256, 32, 32]               0\n",
      "          Conv2d-184          [-1, 256, 32, 32]         589,824\n",
      "          Conv2d-185          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-186          [-1, 256, 32, 32]             512\n",
      "     BatchNorm2d-187          [-1, 256, 32, 32]             512\n",
      "            ReLU-188          [-1, 256, 32, 32]               0\n",
      "            ReLU-189          [-1, 256, 32, 32]               0\n",
      "          Conv2d-190         [-1, 1024, 32, 32]         262,144\n",
      "          Conv2d-191         [-1, 1024, 32, 32]         262,144\n",
      "     BatchNorm2d-192         [-1, 1024, 32, 32]           2,048\n",
      "     BatchNorm2d-193         [-1, 1024, 32, 32]           2,048\n",
      "            ReLU-194         [-1, 1024, 32, 32]               0\n",
      "            ReLU-195         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-196         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-197         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-198          [-1, 256, 32, 32]         262,144\n",
      "          Conv2d-199          [-1, 256, 32, 32]         262,144\n",
      "     BatchNorm2d-200          [-1, 256, 32, 32]             512\n",
      "     BatchNorm2d-201          [-1, 256, 32, 32]             512\n",
      "            ReLU-202          [-1, 256, 32, 32]               0\n",
      "            ReLU-203          [-1, 256, 32, 32]               0\n",
      "          Conv2d-204          [-1, 256, 32, 32]         589,824\n",
      "          Conv2d-205          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-206          [-1, 256, 32, 32]             512\n",
      "     BatchNorm2d-207          [-1, 256, 32, 32]             512\n",
      "            ReLU-208          [-1, 256, 32, 32]               0\n",
      "            ReLU-209          [-1, 256, 32, 32]               0\n",
      "          Conv2d-210         [-1, 1024, 32, 32]         262,144\n",
      "          Conv2d-211         [-1, 1024, 32, 32]         262,144\n",
      "     BatchNorm2d-212         [-1, 1024, 32, 32]           2,048\n",
      "     BatchNorm2d-213         [-1, 1024, 32, 32]           2,048\n",
      "            ReLU-214         [-1, 1024, 32, 32]               0\n",
      "            ReLU-215         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-216         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-217         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-218          [-1, 256, 32, 32]         262,144\n",
      "          Conv2d-219          [-1, 256, 32, 32]         262,144\n",
      "     BatchNorm2d-220          [-1, 256, 32, 32]             512\n",
      "     BatchNorm2d-221          [-1, 256, 32, 32]             512\n",
      "            ReLU-222          [-1, 256, 32, 32]               0\n",
      "            ReLU-223          [-1, 256, 32, 32]               0\n",
      "          Conv2d-224          [-1, 256, 32, 32]         589,824\n",
      "          Conv2d-225          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-226          [-1, 256, 32, 32]             512\n",
      "     BatchNorm2d-227          [-1, 256, 32, 32]             512\n",
      "            ReLU-228          [-1, 256, 32, 32]               0\n",
      "            ReLU-229          [-1, 256, 32, 32]               0\n",
      "          Conv2d-230         [-1, 1024, 32, 32]         262,144\n",
      "          Conv2d-231         [-1, 1024, 32, 32]         262,144\n",
      "     BatchNorm2d-232         [-1, 1024, 32, 32]           2,048\n",
      "     BatchNorm2d-233         [-1, 1024, 32, 32]           2,048\n",
      "            ReLU-234         [-1, 1024, 32, 32]               0\n",
      "            ReLU-235         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-236         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-237         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-238          [-1, 256, 32, 32]         262,144\n",
      "          Conv2d-239          [-1, 256, 32, 32]         262,144\n",
      "     BatchNorm2d-240          [-1, 256, 32, 32]             512\n",
      "     BatchNorm2d-241          [-1, 256, 32, 32]             512\n",
      "            ReLU-242          [-1, 256, 32, 32]               0\n",
      "            ReLU-243          [-1, 256, 32, 32]               0\n",
      "          Conv2d-244          [-1, 256, 32, 32]         589,824\n",
      "          Conv2d-245          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-246          [-1, 256, 32, 32]             512\n",
      "     BatchNorm2d-247          [-1, 256, 32, 32]             512\n",
      "            ReLU-248          [-1, 256, 32, 32]               0\n",
      "            ReLU-249          [-1, 256, 32, 32]               0\n",
      "          Conv2d-250         [-1, 1024, 32, 32]         262,144\n",
      "          Conv2d-251         [-1, 1024, 32, 32]         262,144\n",
      "     BatchNorm2d-252         [-1, 1024, 32, 32]           2,048\n",
      "     BatchNorm2d-253         [-1, 1024, 32, 32]           2,048\n",
      "            ReLU-254         [-1, 1024, 32, 32]               0\n",
      "            ReLU-255         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-256         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-257         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-258          [-1, 256, 32, 32]         262,144\n",
      "          Conv2d-259          [-1, 256, 32, 32]         262,144\n",
      "     BatchNorm2d-260          [-1, 256, 32, 32]             512\n",
      "     BatchNorm2d-261          [-1, 256, 32, 32]             512\n",
      "            ReLU-262          [-1, 256, 32, 32]               0\n",
      "            ReLU-263          [-1, 256, 32, 32]               0\n",
      "          Conv2d-264          [-1, 256, 32, 32]         589,824\n",
      "          Conv2d-265          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-266          [-1, 256, 32, 32]             512\n",
      "     BatchNorm2d-267          [-1, 256, 32, 32]             512\n",
      "            ReLU-268          [-1, 256, 32, 32]               0\n",
      "            ReLU-269          [-1, 256, 32, 32]               0\n",
      "          Conv2d-270         [-1, 1024, 32, 32]         262,144\n",
      "          Conv2d-271         [-1, 1024, 32, 32]         262,144\n",
      "     BatchNorm2d-272         [-1, 1024, 32, 32]           2,048\n",
      "     BatchNorm2d-273         [-1, 1024, 32, 32]           2,048\n",
      "            ReLU-274         [-1, 1024, 32, 32]               0\n",
      "            ReLU-275         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-276         [-1, 1024, 32, 32]               0\n",
      "      Bottleneck-277         [-1, 1024, 32, 32]               0\n",
      "          Conv2d-278          [-1, 512, 32, 32]         524,288\n",
      "          Conv2d-279          [-1, 512, 32, 32]         524,288\n",
      "     BatchNorm2d-280          [-1, 512, 32, 32]           1,024\n",
      "     BatchNorm2d-281          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-282          [-1, 512, 32, 32]               0\n",
      "            ReLU-283          [-1, 512, 32, 32]               0\n",
      "          Conv2d-284          [-1, 512, 16, 16]       2,359,296\n",
      "          Conv2d-285          [-1, 512, 16, 16]       2,359,296\n",
      "     BatchNorm2d-286          [-1, 512, 16, 16]           1,024\n",
      "     BatchNorm2d-287          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-288          [-1, 512, 16, 16]               0\n",
      "            ReLU-289          [-1, 512, 16, 16]               0\n",
      "          Conv2d-290         [-1, 2048, 16, 16]       1,048,576\n",
      "          Conv2d-291         [-1, 2048, 16, 16]       1,048,576\n",
      "     BatchNorm2d-292         [-1, 2048, 16, 16]           4,096\n",
      "     BatchNorm2d-293         [-1, 2048, 16, 16]           4,096\n",
      "          Conv2d-294         [-1, 2048, 16, 16]       2,097,152\n",
      "          Conv2d-295         [-1, 2048, 16, 16]       2,097,152\n",
      "     BatchNorm2d-296         [-1, 2048, 16, 16]           4,096\n",
      "     BatchNorm2d-297         [-1, 2048, 16, 16]           4,096\n",
      "            ReLU-298         [-1, 2048, 16, 16]               0\n",
      "            ReLU-299         [-1, 2048, 16, 16]               0\n",
      "      Bottleneck-300         [-1, 2048, 16, 16]               0\n",
      "      Bottleneck-301         [-1, 2048, 16, 16]               0\n",
      "          Conv2d-302          [-1, 512, 16, 16]       1,048,576\n",
      "          Conv2d-303          [-1, 512, 16, 16]       1,048,576\n",
      "     BatchNorm2d-304          [-1, 512, 16, 16]           1,024\n",
      "     BatchNorm2d-305          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-306          [-1, 512, 16, 16]               0\n",
      "            ReLU-307          [-1, 512, 16, 16]               0\n",
      "          Conv2d-308          [-1, 512, 16, 16]       2,359,296\n",
      "          Conv2d-309          [-1, 512, 16, 16]       2,359,296\n",
      "     BatchNorm2d-310          [-1, 512, 16, 16]           1,024\n",
      "     BatchNorm2d-311          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-312          [-1, 512, 16, 16]               0\n",
      "            ReLU-313          [-1, 512, 16, 16]               0\n",
      "          Conv2d-314         [-1, 2048, 16, 16]       1,048,576\n",
      "          Conv2d-315         [-1, 2048, 16, 16]       1,048,576\n",
      "     BatchNorm2d-316         [-1, 2048, 16, 16]           4,096\n",
      "     BatchNorm2d-317         [-1, 2048, 16, 16]           4,096\n",
      "            ReLU-318         [-1, 2048, 16, 16]               0\n",
      "            ReLU-319         [-1, 2048, 16, 16]               0\n",
      "      Bottleneck-320         [-1, 2048, 16, 16]               0\n",
      "      Bottleneck-321         [-1, 2048, 16, 16]               0\n",
      "          Conv2d-322          [-1, 512, 16, 16]       1,048,576\n",
      "          Conv2d-323          [-1, 512, 16, 16]       1,048,576\n",
      "     BatchNorm2d-324          [-1, 512, 16, 16]           1,024\n",
      "     BatchNorm2d-325          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-326          [-1, 512, 16, 16]               0\n",
      "            ReLU-327          [-1, 512, 16, 16]               0\n",
      "          Conv2d-328          [-1, 512, 16, 16]       2,359,296\n",
      "          Conv2d-329          [-1, 512, 16, 16]       2,359,296\n",
      "     BatchNorm2d-330          [-1, 512, 16, 16]           1,024\n",
      "     BatchNorm2d-331          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-332          [-1, 512, 16, 16]               0\n",
      "            ReLU-333          [-1, 512, 16, 16]               0\n",
      "          Conv2d-334         [-1, 2048, 16, 16]       1,048,576\n",
      "          Conv2d-335         [-1, 2048, 16, 16]       1,048,576\n",
      "     BatchNorm2d-336         [-1, 2048, 16, 16]           4,096\n",
      "     BatchNorm2d-337         [-1, 2048, 16, 16]           4,096\n",
      "            ReLU-338         [-1, 2048, 16, 16]               0\n",
      "            ReLU-339         [-1, 2048, 16, 16]               0\n",
      "      Bottleneck-340         [-1, 2048, 16, 16]               0\n",
      "      Bottleneck-341         [-1, 2048, 16, 16]               0\n",
      "AdaptiveMaxPool2d-342           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n",
      "AdaptiveConcatPool2d-344           [-1, 4096, 1, 1]               0\n",
      "          Lambda-345                 [-1, 4096]               0\n",
      "     BatchNorm1d-346                 [-1, 4096]           8,192\n",
      "         Dropout-347                 [-1, 4096]               0\n",
      "          Linear-348                  [-1, 512]       2,097,664\n",
      "            ReLU-349                  [-1, 512]               0\n",
      "     BatchNorm1d-350                  [-1, 512]           1,024\n",
      "         Dropout-351                  [-1, 512]               0\n",
      "          Linear-352                   [-1, 28]          14,364\n",
      "================================================================\n",
      "Total params: 49,131,036\n",
      "Trainable params: 49,131,036\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.00\n",
      "Forward/backward pass size (MB): 2922.17\n",
      "Params size (MB): 187.42\n",
      "Estimated Total Size (MB): 3113.59\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Resnet4Channel(50).to(device)\n",
    "summary(model, (4, sz, sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resnet4Channel(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (custom_head): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Lambda()\n",
       "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.25)\n",
       "    (4): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5)\n",
       "    (8): Linear(in_features=512, out_features=28, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ClassificationLearner(\n",
    "    data=data,\n",
    "    model=model,\n",
    "    loss_func=F.binary_cross_entropy_with_logits,\n",
    "    #loss_func=FocalLoss(),\n",
    "    path=STAGE_ONE_DATA,    \n",
    "    metrics=[f1_score]\n",
    ")\n",
    "\n",
    "#learn = create_cnn(data=data, arch=model, metrics=[f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.freeze_to(-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 13:09\n",
      "epoch  train_loss  valid_loss  fbeta   \n",
      "1      0.206896    1.793007    0.158405  (13:09)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#learn.fit(1, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 4:19:15\n",
      "epoch  train_loss  valid_loss  fbeta      \n",
      "1      0.160634    1.968509    0.202988     (13:03)\n",
      "2      0.172951    36.358135   0.119728     (13:03)\n",
      "3      0.174315    379.290405  0.145940     (13:01)\n",
      "4      0.177522    6860.312012  0.087006    (13:01)\n",
      "5      0.195291    19.312492   0.290294     (12:59)\n",
      "6      0.199401    3421.173096  0.151579    (13:03)\n",
      "7      0.189825    3890.949951  0.092510    (13:00)\n",
      "8      0.193235    5218.625488  0.085218    (13:00)\n",
      "9      0.185116    615.447876  0.111206     (12:59)\n",
      "10     0.185031    7293.870117  0.123527    (13:00)\n",
      "11     0.188973    368415.000000  0.082437  (13:01)\n",
      "12     0.170449    155.008591  0.040117     (12:58)\n",
      "13     0.166298    204.119202  0.163346     (13:00)\n",
      "14     0.157560    228.819366  0.061087     (12:26)\n",
      "15     0.154693    14.067640   0.107645     (12:33)\n",
      "16     0.149470    48.349648   0.245781     (12:59)\n",
      "17     0.138321    0.274224    0.333268     (12:59)\n",
      "18     0.136218    1.098433    0.345614     (13:01)\n",
      "19     0.129530    0.282952    0.377738     (12:59)\n",
      "20     0.132251    0.308488    0.371300     (12:59)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(20, slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('resnet50_sz512_bs16_unchangedHead')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1129: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "preds,_ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = [' '.join(list([str(i) for i in np.nonzero(row>0.2)[0]])) for row in np.array(preds)]\n",
    "df = pd.DataFrame({'Id':df_test.Id,'Predicted':pred_labels})\n",
    "df.to_csv(SUBMISSIONS/'resnet50_sz512_bs16_unchangedHead.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
